{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "def loadcsv(filename):\n",
    "    lines = csv.reader(open(filename, 'r'))\n",
    "    dataset = list(lines)\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    \n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers]) / float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "    \n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    \n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2) / (2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        \n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    \n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "            \n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    filename = '5.csv'\n",
    "    splitRatio = 0.67\n",
    "    dataset = loadcsv(filename)\n",
    "    \n",
    "    print(\"\\nThe length of the Dataset:\", len(dataset))\n",
    "    \n",
    "    print(\"\\nThe Dataset Splitting into Training and Testing \\n\")\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    \n",
    "    print(\"\\nNumber of Rows in Training Set: {0} rows\".format(len(trainingSet)))\n",
    "    print(\"\\nNumber of Rows in Testing Set: {0} rows\".format(len(testSet)))\n",
    "    \n",
    "    print(\"\\nFirst Five Rows of Training Set:\\n\")\n",
    "    for i in range(0,5):\n",
    "        print(trainingSet[i], \"\\n\")\n",
    "        \n",
    "    print(\"\\nFirst Five Rows of Testing Set:\\n\")\n",
    "    for i in range(0,5):\n",
    "        print(testSet[i], \"\\n\")\n",
    "        \n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    print(\"\\nModel Summaries:\\n\", summaries)\n",
    "    \n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    print(\"\\nPredictions:\\n\", predictions)\n",
    "    \n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print(\"\\nAccuracy: {0}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The length of the Dataset: 768\n",
      "\n",
      "The Dataset Splitting into Training and Testing \n",
      "\n",
      "\n",
      "Number of Rows in Training Set: 514 rows\n",
      "\n",
      "Number of Rows in Testing Set: 254 rows\n",
      "\n",
      "First Five Rows of Training Set:\n",
      "\n",
      "[3.0, 193.0, 70.0, 31.0, 0.0, 34.9, 0.241, 25.0, 1.0] \n",
      "\n",
      "[2.0, 84.0, 50.0, 23.0, 76.0, 30.4, 0.968, 21.0, 0.0] \n",
      "\n",
      "[0.0, 125.0, 96.0, 0.0, 0.0, 22.5, 0.262, 21.0, 0.0] \n",
      "\n",
      "[8.0, 118.0, 72.0, 19.0, 0.0, 23.1, 1.476, 46.0, 0.0] \n",
      "\n",
      "[8.0, 109.0, 76.0, 39.0, 114.0, 27.9, 0.64, 31.0, 1.0] \n",
      "\n",
      "\n",
      "First Five Rows of Testing Set:\n",
      "\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0, 1.0] \n",
      "\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0, 1.0] \n",
      "\n",
      "[4.0, 110.0, 92.0, 0.0, 0.0, 37.6, 0.191, 30.0, 0.0] \n",
      "\n",
      "[10.0, 139.0, 80.0, 0.0, 0.0, 27.1, 1.441, 57.0, 0.0] \n",
      "\n",
      "[5.0, 166.0, 72.0, 19.0, 175.0, 25.8, 0.587, 51.0, 1.0] \n",
      "\n",
      "\n",
      "Model Summaries:\n",
      " {1.0: [(4.935483870967742, 3.6385516917108616), (140.43010752688173, 33.0991623473538), (69.85483870967742, 21.344418935721215), (22.456989247311828, 17.993716007296413), (103.23655913978494, 147.5862659580756), (35.272043010752704, 7.543128114349602), (0.5638118279569896, 0.3734680883938177), (36.55913978494624, 10.605416632963223)], 0.0: [(3.198170731707317, 2.935660167505698), (108.58231707317073, 27.024271423868214), (68.04878048780488, 19.010315846928634), (19.86280487804878, 14.903648365962127), (68.04878048780488, 94.41393698484963), (30.44695121951222, 7.732175309640875), (0.42944817073170743, 0.2900687418205434), (31.15548780487805, 11.673576388324209)]}\n",
      "\n",
      "Predictions:\n",
      " [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "Accuracy: 73.22834645669292%\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
